{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://en.wikipedia.org/wiki/Academy_Award_for_Best_Actor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "s= requests.Session()\n",
    "response = s.get(URL, timeout=10)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View in html\n",
    "pretty_soup = soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_table=soup.find('table', {\"class\":'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of columns in the table\n",
    "for row in right_table.findAll(\"tr\"):\n",
    "    cells = row.findAll('td')\n",
    "\n",
    "len(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows in the table including header\n",
    "rows = right_table.findAll(\"tr\")\n",
    "\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Actor', 'Role(s)', 'Film', 'Ref.']\n"
     ]
    }
   ],
   "source": [
    "header = [th.text.rstrip() for th in rows[0].find_all('th')]\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Data into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "c1=[]\n",
    "c2=[]\n",
    "c3=[]\n",
    "\n",
    "# Scrape each cell and append the data in a list\n",
    "for row in right_table.findAll(\"tr\"):\n",
    "    cells = row.findAll('td')\n",
    "    if len(cells)==4: # Play with this. When cells == 3, you can pull all nominees, and when cells == 4, you can pull the winners\n",
    "        c1.append(cells[0].find(text=True))\n",
    "        c2.append(cells[1].find(text=True))\n",
    "        c3.append(cells[2].find(text=True))\n",
    "        \n",
    "# Check the data\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary\n",
    "d = dict([(x,0) for x in header])\n",
    "\n",
    "# Recall the headers we pulled were: \n",
    "# ['Year', 'Actor', 'Role(s)', 'Film', 'Ref.']\n",
    "\n",
    "# Assign lists to their respective columns\n",
    "d['Actor'] = c1\n",
    "d['Role(s)']= c2\n",
    "d['Film'] = c3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_table = pd.DataFrame(d)\n",
    "\n",
    "# Cheeky workaround to add the years\n",
    "for index, row in df_table.iterrows():\n",
    "    df_table.iloc[index,0] = 1928+index\n",
    "\n",
    "# Drop the unused \"Ref.\" column from the table\n",
    "df_table = df_table.drop('Ref.',axis=1)\n",
    "\n",
    "# Give the DataFrame a meaningful name for analysis\n",
    "best_actor = df_table\n",
    "\n",
    "# Write a copy to .csv so you can access it later\n",
    "best_actor.to_csv(\"best_actor_1-10-2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a Data Frame\n",
    "df = pd.DataFrame(columns=[\"Title\", \"Platform\", \"Metascore\", \"User Score\", \"Release Date\"])\n",
    "\n",
    "for i in range(0,162): # Going on the site, there are 162 pages of games\n",
    "    # In the URL below, we've set it up so we see the condensed view of the site and as the page number is at the end, we can add it to the string\n",
    "    URL = \"https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?view=condensed&sort=desc&page=\"+str(i)\n",
    "    \n",
    "    # Set a user so that metacritic thinks it is being accessed by a browser\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36'\n",
    "    headers = {'User-Agent':user_agent,}\n",
    "\n",
    "    # Include the headers in the request to the page\n",
    "    s = requests.Session()\n",
    "    response = s.get(URL, headers=headers, timeout=10)\n",
    "    \n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    \n",
    "    # Once you figure out the specific scrape for the page, wrap it in a loop\n",
    "    ## Note, the title and platform are formatted a little funny so I've included some code to clean it as it scrapes\n",
    "    ## I left it in just so if you tried you wouldn't be confused about the output\n",
    "    \n",
    "    for games in soup.find_all('div', class_ = \"product_wrap\", limit=100):\n",
    "\n",
    "        # Extract title and platform\n",
    "        title_platform = games.find('a').text\n",
    "        title_platform = str(title_platform).replace(\"\\n\".join([\"  \"]), \"\").strip()\n",
    "\n",
    "        title = title_platform[0:title_platform.find('\\n')]\n",
    "        platform = title_platform[title_platform.find('\\n')+2:len(title_platform)-1]\n",
    "\n",
    "        # Extract Metascore and User score\n",
    "        m_score = games.find('div', class_ = 'metascore_w').text\n",
    "        u_score = games.find('span', class_ = 'textscore').text\n",
    "\n",
    "        # Extract release date\n",
    "        r_date = games.find_all('span', class_= 'data')[1].text\n",
    "        \n",
    "        # Append to the Data Frame\n",
    "        df = df.append({'Title':title, 'Platform':platform ,'Metascore':m_score, 'User Score':u_score, 'Release Date':r_date}, ignore_index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
